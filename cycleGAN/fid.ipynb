{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-05 19:19:03.736431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 19:19:04.357647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64\n",
      "2023-06-05 19:19:04.357721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.7/lib64\n",
      "2023-06-05 19:19:04.357727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/paperspace/anaconda3/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "2023-06-05 19:19:05.711929: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:05.741687: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:05.741860: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:05.742386: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-05 19:19:05.743032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least on"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paperspace/Documents/code/models/cycleGAN/all/train_dataset_input\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:05.743187: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:05.743296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:06.272032: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:06.272314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:06.272538: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-06-05 19:19:06.272729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78962 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:00:05.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import load_dataset\n",
    "from metrics import calculate_metrics\n",
    "\n",
    "# Load test dataset\n",
    "train_ds, test_ds = load_dataset()\n",
    "\n",
    "# # Prepare test dataset for calculating FID\n",
    "# test_ds[0] = test_ds[0].batch(32)\n",
    "# test_ds[1] = test_ds[1].batch(32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1091"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "train_ds_len = 0\n",
    "for img_idx, train_image_set in enumerate((tf.data.Dataset.zip((train_ds[0], train_ds[1])))):\n",
    "    if count % 2 == 0:\n",
    "        train_ds_len += 1\n",
    "    count += 1\n",
    "        \n",
    "train_ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "test_ds_len = 0\n",
    "for img_idx, test_image_set in enumerate((tf.data.Dataset.zip((test_ds[0], test_ds[1])))):\n",
    "    if count % 2 == 0:\n",
    "        test_ds_len += 1\n",
    "    count += 1\n",
    "        \n",
    "test_ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n",
      "WARNING:root:The given value for groups will be overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model_path = '/home/paperspace/Documents/code/results/cycleGAN/all/06032023_14:03:31/gen_g.h5'\n",
    "gen = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model performance on test dataset...\n",
      "The mean SSIM is: 0.753317 +- 0.017314.\n",
      "The mean PSNR is: 20.736832 +- 0.794593.\n",
      "The mean RSME is: 0.184505 +- 0.016949.\n",
      "The mean MAE is: 0.070676 +- 0.008590.\n"
     ]
    }
   ],
   "source": [
    "# Apply trained models on test dataset to calculate mean metrics\n",
    "tf.print(f\"Testing model performance on test dataset...\")\n",
    "metrics_names = ['SSIM', 'PSNR', 'RSME', 'MAE']\n",
    "metrics = {'SSIM': [], \n",
    "        'PSNR': [], \n",
    "        'RSME': [], \n",
    "        'MAE': [],\n",
    "        }\n",
    "\n",
    "count = 1\n",
    "for img_idx, test_image_set in enumerate((tf.data.Dataset.zip((test_ds[0], test_ds[1])))):\n",
    "    if count % 2 == 0:\n",
    "        fake_image_y = gen(test_image_set[0])\n",
    "        calculated_metrics = calculate_metrics(tf.squeeze(fake_image_y, axis=0)[:,:,0], tf.squeeze(test_image_set[1], axis=0)[:,:,0])\n",
    "        \n",
    "        for metric_idx, metric in enumerate(calculated_metrics):\n",
    "            metrics[metrics_names[metric_idx]].append(metric)\n",
    "\n",
    "    count += 1\n",
    "\n",
    "for metric in metrics_names:   \n",
    "    mean_metric = np.mean(np.asarray(metrics[metric]))\n",
    "    std_metric = np.std(np.asarray(metrics[metric]))\n",
    "    tf.print(f\"The mean {metric} is: {mean_metric:2f} +- {std_metric:2f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "def calculate_fid(real_images, generated_images, batch_size=32):\n",
    "    \n",
    "    # Load InceptionV3 model without top classification layer\n",
    "    inception_model = InceptionV3(include_top=False, pooling='avg')\n",
    "\n",
    "    # Calculate activations for real and generated images\n",
    "    real_activations = inception_model.predict(real_images, batch_size=batch_size)\n",
    "    generated_activations = inception_model.predict(generated_images, batch_size=batch_size)\n",
    "\n",
    "    # Calculate mean and covariance of real and generated activations\n",
    "    mu_real = np.mean(real_activations, axis=0)\n",
    "    mu_generated = np.mean(generated_activations, axis=0)\n",
    "    sigma_real = np.cov(real_activations, rowvar=False)\n",
    "    sigma_generated = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "    # Calculate squared Frobenius norm between means\n",
    "    mean_diff = mu_real - mu_generated\n",
    "    mean_squared_norm = np.sum(mean_diff**2)\n",
    "\n",
    "    # Calculate trace of the product of covariances\n",
    "    cov_product = linalg.sqrtm(sigma_real.dot(sigma_generated))\n",
    "    if np.iscomplexobj(cov_product):\n",
    "        cov_product = cov_product.real\n",
    "\n",
    "    # Calculate FID\n",
    "    fid = mean_squared_norm + np.trace(sigma_real + sigma_generated - 2 * cov_product)\n",
    "\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_FID = 0\n",
    "\n",
    "for idx, test_image in enumerate(tf.data.Dataset.zip((test_ds[0], test_ds[1]))):\n",
    "    FID = calculate_fid\n",
    "    mean_FID += FID\n",
    "    \n",
    "mean_FID = mean_FID/idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
